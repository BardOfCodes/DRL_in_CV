{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Markov Chains Monte Carlo </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>What?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Markov Chain Monte Carlo is a technique to solve the problem of sampling from a complicated distribution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Which Kinds of Complicated Distributions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Probability distribution of names of new born child, or car colors in a given residential enclave..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* In Quantum Physics, Probability of finding the system at position $x$ when measured at a time $t$\n",
    " <center><img src=\"img/quantum_carpet.png\" alt=\"Example1\" style=\"width:200px\"/></center>\n",
    "This is a quantum carpet of a particle is a box, starting from a Gaussian state(You can see the Gaussian concentration at the bottom, i.e., at t=0). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Probability of being in a given state in an MDP,\n",
    "\n",
    " <center><img src=\"img/mdp_prob.jpg\" alt=\"Example1\" style=\"width:700px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/eq_of_state.png\" alt=\"Example1\" style=\"width:700px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Claimed to be one of the most influencial algorithms of the 20th century</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/top_1.png\" alt=\"Example1\" style=\"width:700px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"img/top_2.png\" alt=\"Example1\" style=\"width:700px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Why?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Reason 1\n",
    "<CENTER>**Many problems of CV need sampling from complex probability distributions**</CENTER>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Any Expected Value problem on a complex distribution,\n",
    "  * Higher-order CRFs and semi-Markov CRFs\n",
    "  * Post-processing step in even Deep Learning based Models(DeepLab)\n",
    "* Many more examples to be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Reason 2\n",
    "Most RL methods from now on will use MCMC to sample episodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Intuition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Markov Chains\n",
    "http://setosa.io/ev/markov-chains/\n",
    "\n",
    "2) https://stats.stackexchange.com/questions/165/how-would-you-explain-markov-chain-monte-carlo-mcmc-to-a-layperson/51467#51467\n",
    "\n",
    "3) http://twiecki.github.io/blog/2014/01/02/visualizing-mcmc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get into MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain\n",
    "http://setosa.io/ev/markov-chains/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thought Cementing Example"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
