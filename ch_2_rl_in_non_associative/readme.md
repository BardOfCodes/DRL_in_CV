# <center>Reinforcement Learning in Non-Associative setting</center>

#### <center> Reference: Chapter 2, Sutton and Barto</center>

## Contents:

1) **Introduction**
  * Non-Associative Setting?
  * Examples?

2) **Multi-arm Bandit Problems**
  * k-armed bandit problem
  * expected reward
  * exploration vs exploitation

3) **Action Value Methods**
  * Sample Average method
  * greedy and $\epsilon$ greedy
  * The test-bed
  * Non-stationary problems

4) **Improving Exploration in Simple Bandit Problem**
  * Optimistic Initial Values
  * Upper-Confidence Bound Action Selection
  * Gradient Bandit Algorithm
  
# <center>Summary</center>
* We saw how Reinforcement learning is different from other forms of learning.

* We applied reinforcement learning to a very simple problem.

* We saw the importance of balancing exploration and exploitation.