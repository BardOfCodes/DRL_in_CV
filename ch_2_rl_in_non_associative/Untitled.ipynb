{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Reinforcement Learning in Non-Associative setting</center>\n",
    "\n",
    "#### <center> Reference: Chapter 2, Sutton and Barto</center>\n",
    "\n",
    "## Contents:\n",
    "\n",
    "1) **Introduction**\n",
    "  * Non-Associative Setting?\n",
    "  * Examples?\n",
    "\n",
    "2) **Multi-arm Bandit Problems**\n",
    "  * k-armed bandit problem\n",
    "  * expected reward\n",
    "  * exploration vs exploitation\n",
    "\n",
    "3) **Action Value Methods**\n",
    "  * Sample Average method\n",
    "  * greedy and $\\epsilon$ greedy\n",
    "  * The test-bed\n",
    "  * Non-stationary problems\n",
    "\n",
    "4) **Improving Exploration in Simple Bandit Problem**\n",
    "  * Optimistic Initial Values\n",
    "  * Upper-Confidence Bound Action Selection\n",
    "  * Gradient Bandit Algorithm\n",
    "  \n",
    "# <center>Summary</center>\n",
    "* We have seen how Reinforcement learning is different from other forms of learning.<br>\n",
    "* We applied reinforcement learning to a very simple problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
