
# Dynamic programming Methods

### Reference: Chapter 3, Sutton and Barto

## Contents:

1) **Introduction**

2) **Building Blocks of MDP**
	* Markov Property
	* State Transition Matrix
	* Return
	* Discount
	* Value Function

3) **MDP Parameters**
	* Policy in MDP Notations
	* Value Functions in MDP notations

4) **Bellman Expectation Equations**

5) **Bellman Optimality Equations**
