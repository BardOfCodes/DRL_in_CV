{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Value Function Approximation</center>\n",
    "## <center>Part II</center>\n",
    "## <center>Reference: Sutton and Barto;Chapter 9-11</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Table of Contents</center>\n",
    "<br>\n",
    "\n",
    "* **Batch Reinforcement Methods**<br><br>\n",
    "\n",
    "* **Least Squares Policy Iteration(LSPI)**<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Batch Reinforcement Methods</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Batch Reinforcement Methods</center>\n",
    "<br>\n",
    "* Gradient descent is simple and appealing<br><br>\n",
    "* But it is not sample efficient<br><br>\n",
    "* Batch methods seek to find the best fitting value function<br><br>\n",
    "* Given the agent’s experience (“training data”)<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Least Squares Prediction</center>\n",
    "\n",
    "<center><img src=\"img/fa2_slides1.JPG\" alt=\"Multi-armed Bandit\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Stochastic Gradient Descent with Experience Replay</center>\n",
    "\n",
    "<center><img src=\"img/fa2_slides3.JPG\" alt=\"Multi-armed Bandit\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Experience Replay in Deep Q-Networks (DQN)</center>\n",
    "\n",
    "<center><img src=\"img/fa2_slides4.jpg\" alt=\"Multi-armed Bandit\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CV Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Linear Least Squares Prediction</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Linear Least Squares Prediction</center>\n",
    "<br><br>\n",
    "* Experience replay finds least squares solution<br><br>\n",
    "* But it may take many iterations<br><br>\n",
    "* Using linear value function approximation $\\hat{v}(s, w) = x(s)^Tw$<br><br>\n",
    "* We can solve the least squares solution directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Linear Least Squares Prediction</center>\n",
    "\n",
    "<center><img src=\"img/fa2_slides5.JPG\" alt=\"Multi-armed Bandit\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Linear Least Squares Prediction Algorithms</center>\n",
    "\n",
    "<center><img src=\"img/fa2_slides6.JPG\" alt=\"Multi-armed Bandit\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Linear Least Squares Prediction Algorithms</center>\n",
    "\n",
    "<center><img src=\"img/fa2_slides7.JPG\" alt=\"Multi-armed Bandit\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Least Squares Policy Iteration(LSPI)</center>\n",
    "\n",
    "<center><img src=\"img/fa2_slides8.JPG\" alt=\"Multi-armed Bandit\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Least Squares Action-Value Function Approximation</center>\n",
    "\n",
    "<center><img src=\"img/fa2_slides9.JPG\" alt=\"Multi-armed Bandit\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Least Squares Control</center>\n",
    "\n",
    "<center><img src=\"img/fa2_slides10.JPG\" alt=\"Multi-armed Bandit\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Least Squares Q-Learning</center>\n",
    "\n",
    "<center><img src=\"img/fa2_slides11.JPG\" alt=\"Multi-armed Bandit\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## <center>Least Squares Policy Iteration(LSPI) Algorithm</center>\n",
    "\n",
    "<center><img src=\"img/fa2_slides12.JPG\" alt=\"Multi-armed Bandit\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CV Example"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
